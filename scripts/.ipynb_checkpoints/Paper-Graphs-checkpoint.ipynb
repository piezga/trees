{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21e462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b71a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axes.facecolor': 'white', 'axes.edgecolor': 'black', 'axes.grid': False, 'axes.axisbelow': 'line', 'axes.labelcolor': 'black', 'figure.facecolor': 'white', 'grid.color': '#b0b0b0', 'grid.linestyle': '-', 'text.color': 'black', 'xtick.color': 'black', 'ytick.color': 'black', 'xtick.direction': 'out', 'ytick.direction': 'out', 'lines.solid_capstyle': <CapStyle.projecting: 'projecting'>, 'patch.edgecolor': 'black', 'patch.force_edgecolor': False, 'image.cmap': 'viridis', 'font.family': ['sans-serif'], 'font.sans-serif': ['DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', 'sans-serif'], 'xtick.bottom': True, 'xtick.top': False, 'ytick.left': True, 'ytick.right': False, 'axes.spines.left': True, 'axes.spines.bottom': True, 'axes.spines.right': True, 'axes.spines.top': True}\n",
      "{'font.size': 9.600000000000001, 'axes.labelsize': 18.18181818181818, 'axes.titlesize': 9.600000000000001, 'xtick.labelsize': 21.818181818181817, 'ytick.labelsize': 21.818181818181817, 'legend.fontsize': 8.8, 'legend.title_fontsize': 9.600000000000001, 'axes.linewidth': 1.0, 'grid.linewidth': 0.8, 'lines.linewidth': 1.2000000000000002, 'lines.markersize': 4.800000000000001, 'patch.linewidth': 0.8, 'xtick.major.width': 1.0, 'ytick.major.width': 1.0, 'xtick.minor.width': 0.8, 'ytick.minor.width': 0.8, 'xtick.major.size': 4.800000000000001, 'ytick.major.size': 4.800000000000001, 'xtick.minor.size': 3.2, 'ytick.minor.size': 3.2}\n"
     ]
    }
   ],
   "source": [
    "cwidth = 4\n",
    "cheight = cwidth / 1.618 #Divine proportion!\n",
    "\n",
    "label_size = 0\n",
    "tick_size = 0\n",
    "text_size = 0\n",
    "\n",
    "def set_text_size(c):\n",
    "    label_size = 10 * c / 2.2#2.73 #Multiply by 4/2.73 since figures are going to have 2.73 inches in final pdf \n",
    "    #label_size = 12 * c / 2.73 #Multiply by 4/2.73 since figures are going to have 2.73 inches in final pdf \n",
    "    tick_size = 8 * c / 2.2#2.73\n",
    "    text_size = 12 * c / 2.2#2.73\n",
    "    tick_size = 12 * c / 2.2#2.73\n",
    "    \n",
    "    params = {\"axes.labelsize\": label_size, \"font.family\":\"sans-serif\", \"font.serif\":\"Helvetica\",\n",
    "         \"xtick.labelsize\": tick_size, \"ytick.labelsize\":tick_size}\n",
    "    sns.set_context(\"paper\", rc=params)\n",
    "    return label_size, tick_size, text_size\n",
    "\n",
    "label_size, tick_size, text_size = set_text_size(cwidth)\n",
    "\n",
    "#path = \"../articulo/v3/graphs/\"\n",
    "#datapath = \"larr_data/larremore_data/\"\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "#plt.rc('xtick', labelsize=8)\n",
    "#plt.rc('ytick', labelsize=8)\n",
    "#plt.rc('axes', labelsize=8)\n",
    "\n",
    "print(sns.axes_style())\n",
    "print(sns.plotting_context())\n",
    "\n",
    "def set_ticks(axis, x, ticks, fmt=1):\n",
    "    if (x==\"x\"):\n",
    "        axis.set_xticks(ticks)\n",
    "        axis.set_xticklabels([\"{0:.{1}f}\".format(t, fmt) for t in ticks])\n",
    "    else:\n",
    "        axis.set_yticks(ticks)\n",
    "        axis.set_yticklabels([\"{0:.{1}f}\".format(t, fmt) for t in ticks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "277f95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marchenko-Pastur\n",
    "#The distribution receives two parameters, l is the x vector, g is (1.0*N)/T,\n",
    "#where N is the system size and T the total number of steps.\n",
    "def marchpast(l, g):\n",
    "    \"Marchenko-Pastur distribution\"\n",
    "    def m0(a):\n",
    "        \"Element wise maximum of (a,0)\"\n",
    "        return np.maximum(a, np.zeros_like(a))\n",
    "    gplus=(1+g**0.5)**2\n",
    "    gminus=(1-g**0.5)**2\n",
    "    return np.sqrt(  m0(gplus  - l) *  m0(l- gminus)) / ( 2*np.pi*g*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6999116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def MarchenkoPastur(C,N,T,remove_largest=True):\n",
    "    r\"\"\"Uses Marchenko-Pastur law to remove noise.\n",
    "        remove_largest (bool), optional\n",
    "            If ``False``, all the eigenvectors associated to the\n",
    "            significant eigenvalues will be used to reconstruct the\n",
    "            de-noised empirical correlation matrix. If ``True``, the\n",
    "            eigenvector associated to the largest eigenvalue (normally\n",
    "            known as the ``market`` mode, [2]) is going to be excluded from\n",
    "            the recontruction step.  metric_distance (bool), optional: If\n",
    "            ``False``, a signed graph is obtained.  The weights associated\n",
    "            to the edges represent the de-noised correlation coefficient\n",
    "            :math:`\\rho_{i,j}` between time series :math:`i` and :math:`j`.\n",
    "            If ``True``, the correlation is transformed by defining a\n",
    "            metric distance between each pair of nodes where :math:`d_{i,j}\n",
    "            = \\sqrt{2(1-\\rho_{i,j})}` as proposed in [3].  threshold_type\n",
    "            (str): Which thresholding function to use on the matrix of\n",
    "            weights. See `netrd.utilities.threshold.py` for\n",
    "            documentation. Pass additional arguments to the thresholder\n",
    "            using ``**kwargs``.\"\"\"\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "           \n",
    "    if N > T:\n",
    "        raise ValueError(\"L must be greater or equal than N.\")\n",
    "\n",
    "    Q = T / N\n",
    "    w, v = np.linalg.eigh(C)  # Spectral decomposition of C\n",
    "    \n",
    "    w_min = 1 + 1 / Q - 2 * np.sqrt(1 / Q)\n",
    "    w_max = 1 + 1 / Q + 2 * np.sqrt(1 / Q)\n",
    "\n",
    "    selected = (w < w_min) | (w > w_max)\n",
    "\n",
    "    if remove_largest:\n",
    "        selected[-1] = False\n",
    "\n",
    "    w_signal = w[selected]\n",
    "    v_signal = v[:, selected]\n",
    "\n",
    "    C_new = v_signal.dot(np.diag(w_signal)).dot(v_signal.T)\n",
    "    print(w_min,w_max)\n",
    "    return C_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2874700b-834e-41f1-8c49-62184dac9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_29523/3267765548.py:18: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  = \\sqrt{2(1-\\rho_{i,j})}` as proposed in [3].  threshold_type\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def MarchenkoPastur(C,N,T,remove_largest=True):\n",
    "    r\"\"\"Uses Marchenko-Pastur law to remove noise.\n",
    "        remove_largest (bool), optional\n",
    "            If ``False``, all the eigenvectors associated to the\n",
    "            significant eigenvalues will be used to reconstruct the\n",
    "            de-noised empirical correlation matrix. If ``True``, the\n",
    "            eigenvector associated to the largest eigenvalue (normally\n",
    "            known as the ``market`` mode, [2]) is going to be excluded from\n",
    "            the recontruction step.  metric_distance (bool), optional: If\n",
    "            ``False``, a signed graph is obtained.  The weights associated\n",
    "            to the edges represent the de-noised correlation coefficient\n",
    "            :math:`\\rho_{i,j}` between time series :math:`i` and :math:`j`.\n",
    "            If ``True``, the correlation is transformed by defining a\n",
    "            metric distance between each pair of nodes where :math:`d_{i,j}\n",
    "            = \\sqrt{2(1-\\rho_{i,j})}` as proposed in [3].  threshold_type\n",
    "            (str): Which thresholding function to use on the matrix of\n",
    "            weights. See `netrd.utilities.threshold.py` for\n",
    "            documentation. Pass additional arguments to the thresholder\n",
    "            using ``**kwargs``.\"\"\"\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "           \n",
    "    if N > T:\n",
    "        raise ValueError(\"L must be greater or equal than N.\")\n",
    "\n",
    "    Q = T / N\n",
    "    w, v = np.linalg.eigh(C)  # Spectral decomposition of C\n",
    "    \n",
    "    w_min = 1 + 1 / Q - 2 * np.sqrt(1 / Q)\n",
    "    w_max = 1 + 1 / Q + 2 * np.sqrt(1 / Q)\n",
    "\n",
    "    selected = (w < w_min) | (w > w_max)\n",
    "\n",
    "    if remove_largest:\n",
    "        selected[-1] = False\n",
    "\n",
    "    w_signal = w[selected]\n",
    "    v_signal = v[:, selected]\n",
    "\n",
    "    C_new = v_signal.dot(np.diag(w_signal)).dot(v_signal.T)\n",
    "    print(w_min,w_max)\n",
    "    return C_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b674795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from tqdm import tqdm\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "\n",
    "def entropy(G,steps):\n",
    "    w=nx.laplacian_spectrum(G)\n",
    "    t1=np.log10(1/np.max(w[w>1e-10]))\n",
    "    t2=np.log10(10/np.min(w[w>1e-10]))\n",
    "    t = np.logspace(t1,t2, int(steps))\n",
    "    cont=0\n",
    "    S=np.zeros(len(t))\n",
    "    VarL=np.zeros(len(t))\n",
    "    #N=len(HG.nodes())\n",
    "    \n",
    "    #L=nx.laplacian_matrix(G)\n",
    "    #L1=L.todense()      \n",
    "    Len=np.zeros(len(t))\n",
    "\n",
    "    \n",
    "    for tau in tqdm(t):      \n",
    "        Tr=np.nansum(np.exp(-tau*w))\n",
    "        T1=np.divide(np.exp(-w*tau),Tr)\n",
    "        S[cont]=-np.nansum(T1*np.log(T1))/np.log(N)\n",
    "        Med=np.nansum(np.multiply(w,np.exp(-tau*w)))/Tr\n",
    "        Sqr=np.nansum(np.multiply(np.multiply(w,w),np.exp(-tau*w)))/Tr\n",
    "        VarL[cont]=(Sqr-Med*Med)\n",
    "        cont=cont+1\n",
    "        \n",
    "    dS=np.log(N)*np.diff(1-S)/np.diff(np.log(t))\n",
    "    return 1-S,dS,VarL, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7279bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "#from scipy.linalg import expm, sinm, cosm\n",
    "from scipy.sparse.linalg import expm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def entropyF(G,steps):\n",
    "    w=nx.laplacian_spectrum(G)\n",
    "    t1=np.log10(1/np.max(w[w>1e-10]))\n",
    "    t2=np.log10(10/np.min(w[w>1e-10]))\n",
    "    t = np.logspace(t1,t2, int(steps))\n",
    "    cont=0\n",
    "    S=np.zeros(len(t))\n",
    "    VarL=np.zeros(len(t))\n",
    "    C=np.zeros(len(t))\n",
    "    CVar=np.zeros(len(t))\n",
    "    N=len(G.nodes())\n",
    "    \n",
    "    L=nx.laplacian_matrix(G)\n",
    "    L1=L.todense()    \n",
    "    Len=np.zeros(len(t))\n",
    "\n",
    "    \n",
    "    for tau in tqdm(t):\n",
    "        \n",
    "        num=expm((-tau*L1))\n",
    "        den=np.trace(num)\n",
    "        rho=num/den\n",
    "        #rho=np.copy(1/rho)#1/adj2\n",
    "        #mat = np.maximum(rho, rho.transpose() )\n",
    "        #np.fill_diagonal(mat, 0)\n",
    "        #dists = squareform(mat)\n",
    "        #linkage_matrix = linkage(dists, \"average\")\n",
    "        #tmax=linkage_matrix[::, 2][-1]#+0.01*linkage_matrix[::, 2][-1]\n",
    "        #linkage_matrix = linkage(dists/tmax, \"average\")\n",
    "        #tmin=linkage_matrix[::, 2][0]\n",
    "        #tmax=linkage_matrix[::, 2][-1]\n",
    "        #Len[cont]=(tmax)-(tmin)\n",
    "        \n",
    "        \n",
    "        \n",
    "        Tr=np.nansum(np.exp(-tau*w))\n",
    "        T1=np.divide(np.exp(-w*tau),Tr)\n",
    "        S[cont]=-np.nansum(T1*np.log(T1))/np.log(N)\n",
    "        Med=np.nansum(np.multiply(w,np.exp(-tau*w)))/Tr\n",
    "        Sqr=np.nansum(np.multiply(np.multiply(w,w),np.exp(-tau*w)))/Tr\n",
    "        VarL[cont]=(Sqr-Med*Med)\n",
    "        \n",
    "        \n",
    "        \n",
    "        Med1=np.zeros(N)\n",
    "        Med1[:]=Med\n",
    "        l1=np.diag(Med1)\n",
    "        DL=L.toarray()-l1\n",
    "        DL2=np.matmul(DL,DL)\n",
    "        Gamma=np.multiply(rho,np.transpose(DL2))\n",
    "        C[cont]=np.sum(np.sum(Gamma))*tau*tau\n",
    "        CVar[cont]=np.std(Gamma.sum(axis=1))/np.mean(Gamma.sum(axis=1))\n",
    "        \n",
    "        cont=cont+1\n",
    "        \n",
    "    dS=np.log(N)*np.diff(1-S)/np.diff(np.log(t))\n",
    "    return 1-S,dS,VarL,C,CVar, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "784a4a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'powerlaw'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpowerlaw\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pdist,squareform\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chain\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'powerlaw'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "for j in tqdm(range(1,9)):\n",
    "    print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        #np.random.shuffle(U)\n",
    "        UVec[i]=U\n",
    "    Corr1=scipy.stats.spearmanr(UVec,axis=1)\n",
    "    #Corr=np.corrcoef(UVec)\n",
    "    w=np.abs(np.linalg.eigvalsh(Corr1.correlation))\n",
    "    eigs=np.concatenate((eigs, w), axis=None)\n",
    "\n",
    "np.savetxt('SpearmanCorr_l'+str(Lb)+'_Eigs_average', eigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "\n",
    "fit1=powerlaw.Fit(eigs,xmin=1e-1,xmax=2*np.max(eigs),discrete=False,density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "\n",
    "T=len(U)\n",
    "print(T)\n",
    "gamma=(1.0*nspec)/T\n",
    "print(gamma)\n",
    "x=np.arange(1e-4, 1e2, 0.001)\n",
    "data=marchpast(x,gamma)\n",
    "data[data == 0] = 'nan'\n",
    "\n",
    "plt.plot(x, data)\n",
    "\n",
    "probc,binsc=np.histogram(eigs,np.arange(np.min(eigs),np.max(eigs),0.1),density=True)\n",
    "probc[probc == 0] = 'nan'\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "probc[probc == 0] = 'nan'\n",
    "plt.plot(binsc,probc,marker='o',lw=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from farrow_and_ball import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import cm\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.ticker\n",
    "import networkx as nx\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(8,3.5)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "     AB\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "nspec=100\n",
    "lv=[10,20,25,50]\n",
    "pal = sns.color_palette('magma', n_colors=len(lv), desat=1.0)\n",
    "\n",
    "for l in lv:\n",
    "    Eigs=pd.read_csv('PearsonCorr_l'+str(l)+'_Eigs_average',delimiter=' ',header=None)[0]\n",
    "    fit1=powerlaw.Fit(Eigs,xmin=1e-1,xmax=2*np.max(Eigs),discrete=False,\n",
    "                      density=True,fit_method='KS')\n",
    "    binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "    probc[probc == 0] = 'nan'\n",
    "    binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "    c1=pal.pop(0)\n",
    "    ax_dict['A'].plot(binsc,probc,marker='o',lw=2,label=str(l)+'m',color=c1)\n",
    "    T=(1000/l)*(500/l)\n",
    "    gamma=(1.0*nspec)/T\n",
    "    x=np.arange(1e-4, 1e2, 0.001)\n",
    "    data=marchpast(x,gamma)\n",
    "    data[data == 0] = 'nan'\n",
    "    ax_dict['A'].plot(x, data,ls='--',color=c1)\n",
    "\n",
    "ax_dict['A'].legend()\n",
    "ax_dict['A'].set_xscale('log')\n",
    "ax_dict['A'].set_yscale('log')\n",
    "ax_dict['A'].set_xticks([1e-1,1e0,1e1])\n",
    "ax_dict['A'].set_yticks([1e-4,1e-2,1e0])\n",
    "ax_dict['A'].set_ylabel(r'$P(\\lambda)$')\n",
    "ax_dict['A'].set_xlabel(r'$\\lambda$')\n",
    "\n",
    "\n",
    "pal = sns.color_palette('magma', n_colors=len(lv), desat=1.0)\n",
    "for l in lv:\n",
    "    Eigs=pd.read_csv('SpearmanCorr_l'+str(l)+'_Eigs_average',delimiter=' ',header=None)[0]\n",
    "    fit1=powerlaw.Fit(Eigs,xmin=1e-1,xmax=2*np.max(Eigs),discrete=False,density=True,fit_method='KS')\n",
    "    binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "    probc[probc == 0] = 'nan'\n",
    "    binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "    c1=pal.pop(0)\n",
    "    ax_dict['B'].plot(binsc,probc,marker='o',lw=2,color=c1)\n",
    "    T=(1000/l)*(500/l)\n",
    "    gamma=(1.0*nspec)/T\n",
    "    x=np.arange(1e-4, 1e2, 0.001)\n",
    "    data=marchpast(x,gamma)\n",
    "    data[data == 0] = 'nan'\n",
    "    ax_dict['B'].plot(x, data,ls='--',color=c1)\n",
    "ax_dict['B'].set_xscale('log')\n",
    "ax_dict['B'].set_yscale('log')\n",
    "ax_dict['B'].set_xticks([1e-1,1e0,1e1])\n",
    "ax_dict['B'].set_yticks([1e-4,1e-2,1e0])\n",
    "ax_dict['B'].set_ylabel(r'$P(\\lambda)$')\n",
    "ax_dict['B'].set_xlabel(r'$\\lambda$')\n",
    "\n",
    "\n",
    "ax_dict['A'].text(-0.4, 1.03, '(a)', transform=ax_dict['A'].transAxes, \n",
    "            size=20)\n",
    "ax_dict['B'].text(-0.4, 1.03, '(b)', transform=ax_dict['B'].transAxes, \n",
    "            size=20)\n",
    "\n",
    "#plt.savefig('Correlations.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i in range(nspec):\n",
    "    nm=Recount[i][1]\n",
    "    N=Recount[i][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "    #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "    U=np.array((list(chain.from_iterable(hist))))\n",
    "    #np.random.shuffle(U)\n",
    "    UVec[i]=U\n",
    "#Corr1=scipy.stats.spearmanr(UVec,axis=1)\n",
    "Corr=np.corrcoef(UVec)\n",
    "#w=np.abs(np.linalg.eigvalsh(Corr1.correlation))\n",
    "#eigs=np.concatenate((eigs, w), axis=None)\n",
    "plt.imshow(Corr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08294a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=100\n",
    "T=(Lx/Lb)*(Ly/Lb)\n",
    "C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247edad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(C1,cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "fig=plt.figure(constrained_layout=True,figsize=(12,6))\n",
    "\n",
    "pearson1=np.copy(C1)\n",
    "pearson1[pearson1<0]=0\n",
    "G = nx.from_numpy_array(np.abs(pearson1))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "#nx.draw(G,node_size=15,width=0.05,edge_color='gray')\n",
    "\n",
    "#G = nx.karate_club_graph()\n",
    "L=nx.laplacian_matrix(G)\n",
    "#L=nx.laplacian_matrix(G)\n",
    "L1=L.todense()\n",
    "w=1/nx.laplacian_spectrum(G)\n",
    "\n",
    "#Put a small value of tau here, we want macro-clusters\n",
    "#Control that clusters are stable along different values of tau\n",
    "#Th controls the threshold in the dendrogram, linkage can be changed from 'average' to 'complete'\n",
    "#Control also that this does not change the results\n",
    "tau=1e-3\n",
    "\n",
    "num=expm((-tau*L1))\n",
    "den=np.trace(num)\n",
    "rho=num/den\n",
    "\n",
    "Trho=np.copy(1.0/rho)#1/adj2\n",
    "Trho=np.tril(Trho) + np.triu(Trho.T, 1)\n",
    "#Trho = np.maximum(Trho, Trho.transpose() )\n",
    "np.fill_diagonal(Trho, 0)\n",
    "\n",
    "dists = squareform(Trho)\n",
    "linkage_matrix = linkage(dists, \"ward\")\n",
    "labelList = [i+1 for i in range(0, len(G.nodes()))]\n",
    "tmax=linkage_matrix[::, 2][-1]#+0.01*linkage_matrix[::, 2][-1]\n",
    "linkage_matrix = linkage(dists/tmax, \"ward\")\n",
    "Th=1e-4\n",
    "dendrogram(linkage_matrix,labels=labelList,leaf_rotation=0,color_threshold=Th,above_threshold_color='k',leaf_font_size=10)\n",
    "CM=fcluster(linkage_matrix, t=Th, criterion='distance')\n",
    "\n",
    "tmin=linkage_matrix[::, 2][0]-0.2*linkage_matrix[::, 2][0]\n",
    "tmax=linkage_matrix[::, 2][-1]+0.1*linkage_matrix[::, 2][-1]\n",
    "\n",
    "plt.ylim(tmin,tmax)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdf23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "idx   = np.argsort(CM)\n",
    "N=len(idx)\n",
    "comm = np.sort(CM)\n",
    "A2 = [[C1[i][j] for j in idx] for i in idx]\n",
    "\n",
    "# define your scale, with white at zero\n",
    "vmin = -0.5\n",
    "vmax = 0.5#np.max(A2)\n",
    "norm = colors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "plt.imshow(A2,cmap='RdBu_r',rasterized='True',interpolation=None,norm=norm)\n",
    "plt.colorbar()\n",
    "#plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "pal = sns.color_palette('Spectral', n_colors=8, desat=1.0)\n",
    "\n",
    "\n",
    "for j in tqdm(range(1,9)):\n",
    "    print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        #np.random.shuffle(U)\n",
    "        UVec[i]=U\n",
    "    Corr=np.corrcoef(UVec)\n",
    "    N=nspec\n",
    "    T=(Lx/Lb)*(Ly/Lb)\n",
    "    C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n",
    "    pearson1=np.copy(C1)\n",
    "    pearson1[pearson1<0]=0\n",
    "    G = nx.from_numpy_array(np.abs(pearson1))\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    [S1,dS1,VarL1,t1]=entropy(G,1000)\n",
    "    #[S1,dS1,VarL1,C1,CVar1,t1]=entropyF(G,300)\n",
    "    #plt.plot(t1,S1,label='Census '+str(j),color=c1)\n",
    "    t11 = (t1[1:]+t1[:-1])/2.0\n",
    "    c1=pal.pop(0)\n",
    "    plt.plot(t11,dS1,ls='-',color=c1,label='Census '+str(j))\n",
    "    #plt.plot(t1,1/CVar1,ls='--',color=c1,label='Census '+str(j))\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('1-S')\n",
    "plt.xlabel(r'$\\tau$')\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(CM)))\n",
    "index=np.where(CM==1)[0]\n",
    "print(index)\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "\n",
    "print(Nombres[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(9,3.5)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AABBCC\n",
    "    AABBDD\n",
    "    \"\"\"\n",
    ")\n",
    "#fig = plt.figure(constrained_layout=True,figsize=(10, 10))\n",
    "#ax_dict = fig.subplot_mosaic(layout)\n",
    "    \n",
    "#Take CMAP\n",
    "cmap1 = cmocean.cm.delta   #Green/blue\n",
    "cmap2 = cmocean.cm.balance #Red/blue\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i in range(nspec):\n",
    "    nm=Recount[i][1]\n",
    "    N=Recount[i][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "    #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "    U=np.array((list(chain.from_iterable(hist))))\n",
    "    #np.random.shuffle(U)\n",
    "    UVec[i]=U\n",
    "#Corr1=scipy.stats.spearmanr(UVec,axis=1)\n",
    "Corr=np.corrcoef(UVec)\n",
    "N=100\n",
    "T=(Lx/Lb)*(Ly/Lb)\n",
    "C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n",
    "\n",
    "# define your scale, with white at zero\n",
    "vmin = -0.5\n",
    "vmax = 0.5#np.max(A2)\n",
    "norm = colors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "pearson1=np.copy(C1)\n",
    "pearson1[pearson1<0]=0\n",
    "G = nx.from_numpy_array(np.abs(pearson1))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "L=nx.laplacian_matrix(G)\n",
    "L1=L.todense()\n",
    "w=1/nx.laplacian_spectrum(G)\n",
    "\n",
    "#Put a small value of tau here, we want macro-clusters\n",
    "#Control that clusters are stable along different values of tau\n",
    "#Th controls the threshold in the dendrogram, linkage can be changed from 'average' to 'complete'\n",
    "#Control also that this does not change the results\n",
    "tau=1e-3\n",
    "\n",
    "num=expm((-tau*L1))\n",
    "den=np.trace(num)\n",
    "rho=num/den\n",
    "\n",
    "Trho=np.copy(1.0/rho)#1/adj2\n",
    "Trho=np.tril(Trho) + np.triu(Trho.T, 1)\n",
    "np.fill_diagonal(Trho, 0)\n",
    "\n",
    "dists = squareform(Trho)\n",
    "linkage_matrix = linkage(dists, \"complete\")\n",
    "labelList = [i+1 for i in range(0, len(G.nodes()))]\n",
    "tmax=linkage_matrix[::, 2][-1]#+0.01*linkage_matrix[::, 2][-1]\n",
    "linkage_matrix = linkage(dists/tmax, \"complete\")\n",
    "Th=1e-4\n",
    "dendrogram(linkage_matrix,labels=labelList,ax=ax_dict['D'],leaf_rotation=0,orientation='top',\n",
    "           color_threshold=Th,above_threshold_color='k',leaf_font_size=10)\n",
    "CM=fcluster(linkage_matrix, t=Th, criterion='distance')\n",
    "\n",
    "idx   = np.argsort(CM)\n",
    "N=len(idx)\n",
    "comm = np.sort(CM)\n",
    "A2 = [[C1[i][j] for j in idx] for i in idx]\n",
    "\n",
    "im=ax_dict['A'].imshow(Corr,cmap=cmap2,rasterized='True',interpolation=None,norm=norm)\n",
    "ax_dict['A'].set_xticks([0,50,100])\n",
    "ax_dict['A'].set_yticks([0,50,100])\n",
    "ax_dict['A'].set_title(r'Pearson Corr. $\\ell=50m$',fontsize=12)\n",
    "ax_dict['A'].text(-0.23, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "im2=ax_dict['B'].imshow(A2,cmap=cmap2,rasterized='True',interpolation=None,norm=norm)\n",
    "ax_dict['B'].set_xticks([0,50,100])\n",
    "ax_dict['B'].set_yticks([0,50,100])\n",
    "ax_dict['B'].set_title(r'Filtered Corr. $\\ell=50m$',fontsize=12)\n",
    "ax_dict['B'].text(-0.23, 1.03, 'B', transform=ax_dict['B'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "bounds = _grid_communities(CM)\n",
    "bounds[0] += 0.2\n",
    "bounds[-1] -= 0.2\n",
    "for n, edge in enumerate(np.diff(bounds)):\n",
    "        ax_dict['B'].add_patch(patches.Rectangle((bounds[n], bounds[n]),\n",
    "                                       edge, edge, fill=False, linewidth=1,ls='--',\n",
    "                                       edgecolor='black'))\n",
    "\n",
    "\n",
    "#Specific Heat Calculation\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "pal = sns.color_palette('Spectral', n_colors=8, desat=1.0)\n",
    "\n",
    "\n",
    "for j in tqdm(range(1,9)):\n",
    "    print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        #np.random.shuffle(U)\n",
    "        UVec[i]=U\n",
    "    Corr=np.corrcoef(UVec)\n",
    "    N=nspec\n",
    "    T=(Lx/Lb)*(Ly/Lb)\n",
    "    C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n",
    "    pearson1=np.copy(C1)\n",
    "    pearson1[pearson1<0]=0\n",
    "    G = nx.from_numpy_array(np.abs(pearson1))\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    [S1,dS1,VarL1,t1]=entropy(G,1000)\n",
    "    #[S1,dS1,VarL1,C1,CVar1,t1]=entropyF(G,300)\n",
    "    #plt.plot(t1,S1,label='Census '+str(j),color=c1)\n",
    "    t11 = (t1[1:]+t1[:-1])/2.0\n",
    "    c1=pal.pop(0)\n",
    "    ax_dict['C'].plot(t11,dS1,ls='-',color=c1,label='Census '+str(j))\n",
    "    #plt.plot(t1,1/CVar1,ls='--',color=c1,label='Census '+str(j))\n",
    "\n",
    "#ax_dict['C'].legend()\n",
    "ax_dict['C'].set_ylabel('C')\n",
    "ax_dict['C'].set_xlabel(r'$\\tau$')\n",
    "ax_dict['C'].set_xscale('log')\n",
    "#plt.yscale('log')\n",
    "ax_dict['C'].text(-0.23, 1.03, 'C', transform=ax_dict['C'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "\n",
    "ax_dict['D'].set_xscale('linear')\n",
    "tmin=linkage_matrix[::, 2][0]-0.2*linkage_matrix[::, 2][0]\n",
    "tmax=linkage_matrix[::, 2][-1]+0.1*linkage_matrix[::, 2][-1]\n",
    "ax_dict['D'].set_ylim(tmin,tmax)\n",
    "ax_dict['D'].axhline(y = Th, color = '#ED2939', linestyle = '--')\n",
    "ax_dict['D'].set_ylabel(r'$\\mathcal{D}/\\mathcal{D}_{max}$')\n",
    "ax_dict['D'].set_xlabel('Node index')\n",
    "ax_dict['D'].set_yscale('log')\n",
    "ax_dict['D'].set_yticks([1e-4,1e-2,1e0])\n",
    "ax_dict['D'].set_xticks([])\n",
    "ax_dict['D'].text(-0.5, 1.03, 'D', transform=ax_dict['D'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#plt.colorbar(im, ax=ax_dict['A'])\n",
    "#plt.colorbar(im2, ax=ax_dict['B'])\n",
    "\n",
    "\n",
    "plt.savefig('BCI-Matrices.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d43445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(9,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter graph\n",
    "N = 2000\n",
    "X = np.random.uniform(-1, 1, N)\n",
    "Y = np.sqrt(1-X**2)*random.choice([-1,1],N)\n",
    "Z = np.random.uniform(-2, 2, N)\n",
    "ax.scatter(X, Y, Z)\n",
    "\n",
    "# Cylinder\n",
    "x=np.linspace(-1, 1, 100)\n",
    "z=np.linspace(-2, 2, 100)\n",
    "Xc, Zc=np.meshgrid(x, z)\n",
    "Yc = np.sqrt(1-Xc**2)\n",
    "\n",
    "# Draw parameters\n",
    "rstride = 15\n",
    "cstride = 5\n",
    "ax.plot_surface(Xc, Yc, Zc, alpha=0.5, linewidth=1,edgecolors='black', rstride=rstride, cstride=cstride,color='lightblue')\n",
    "ax.plot_surface(Xc, -Yc, Zc, alpha=0.5, linewidth=1,edgecolors='black',rstride=rstride, cstride=cstride,color='lightblue')\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ac222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmocean\n",
    "\n",
    "BCI = pd.read_csv(\"bcitree8.dat\",delimiter=' ',header=None) \n",
    "Names = pd.read_csv(\"Names_BCI.csv\",delimiter=',',header=None) \n",
    "\n",
    "nms=Names[0]\n",
    "Fnms=Names[2]\n",
    "Nmbr=Names[1]\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(10,6)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AABB\n",
    "    CCDD\n",
    "    \"\"\"\n",
    ")\n",
    "im = plt.imread('Level.png')\n",
    "#Plot A\n",
    "implot = ax_dict['A'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "index=np.where(CM==4)[0]\n",
    "pal = sns.color_palette('cmo.algae', n_colors=len(index), desat=1.0)\n",
    "\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "for nm in Nombres[index]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    i=int(np.where(nms==nm)[0])\n",
    "    if (i>2):\n",
    "        ax_dict['A'].scatter(filt[0],filt[1],s=10/(len(index)*np.log10(len(filt))),\n",
    "                         rasterized=True,marker='.',label=Fnms[i],color='forestgreen')\n",
    "\n",
    "ax_dict['A'].set_xlim(0,1000)\n",
    "ax_dict['A'].set_ylim(0,500)\n",
    "ax_dict['A'].set_title('Old Forest, Slope')\n",
    "ax_dict['A'].text(-0.05, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "\n",
    "#Figure B\n",
    "implot = ax_dict['B'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "index=np.where(CM==13)[0]\n",
    "pal = sns.color_palette('cmo.algae', n_colors=len(index), desat=1.0)\n",
    "pal.reverse()\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "for nm in Nombres[index]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    i=int(np.where(nms==nm)[0])\n",
    "    if (i>2):\n",
    "        ax_dict['B'].scatter(filt[0],filt[1],s=5/(len(index)*np.log10(len(filt))),\n",
    "                         rasterized=True,marker='.',label=Fnms[i],color='forestgreen')\n",
    "\n",
    "ax_dict['B'].set_xlim(0,1000)\n",
    "ax_dict['B'].set_ylim(0,500)\n",
    "ax_dict['B'].set_title('Old Forest, Streamside')\n",
    "ax_dict['B'].text(-0.05, 1.03, 'B', transform=ax_dict['B'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#Figure C\n",
    "implot = ax_dict['C'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "index=np.where(CM==9)[0]\n",
    "pal = sns.color_palette('cmo.algae', n_colors=len(index), desat=1.0)\n",
    "pal.reverse()\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "for nm in Nombres[index]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    i=int(np.where(nms==nm)[0])\n",
    "    if (i>2):\n",
    "        ax_dict['C'].scatter(filt[0],filt[1],s=20/(len(index)*np.log10(len(filt))),\n",
    "                         rasterized=True,marker='.',label=Fnms[i],color='forestgreen')\n",
    "\n",
    "ax_dict['C'].set_xlim(0,1000)\n",
    "ax_dict['C'].set_ylim(0,500)\n",
    "ax_dict['C'].set_title('Old Forest, Low plateau')\n",
    "ax_dict['C'].text(-0.05, 1.03, 'C', transform=ax_dict['C'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#Figure D\n",
    "implot = ax_dict['D'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "index=np.where(CM==1)[0]\n",
    "pal = sns.color_palette('cmo.algae', n_colors=len(index), desat=1.0)\n",
    "pal.reverse()\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "for nm in Nombres[index]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    i=int(np.where(nms==nm)[0])\n",
    "    if (i>2):\n",
    "        ax_dict['D'].scatter(filt[0],filt[1],s=35/(len(index)*np.log10(len(filt))),\n",
    "                         rasterized=True,marker='.',label=Fnms[i],color='forestgreen')\n",
    "\n",
    "ax_dict['D'].set_xlim(0,1000)\n",
    "ax_dict['D'].set_ylim(0,500)\n",
    "ax_dict['D'].set_title('Old Forest, Swamp')\n",
    "ax_dict['D'].text(-0.05, 1.03, 'D', transform=ax_dict['D'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "#plt.savefig('Communities.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.choose_colorbrewer_palette('diverging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BCI = pd.read_csv(\"bcitree8.dat\",delimiter=' ',header=None) \n",
    "Names = pd.read_csv(\"Names_BCI.csv\",delimiter=',',header=None) \n",
    "\n",
    "nms=Names[0]\n",
    "Fnms=Names[2]\n",
    "Nmbr=Names[1]\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(10,6)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AACC\n",
    "    BBDD\n",
    "    \"\"\"\n",
    ")\n",
    "im = plt.imread('Level.png')\n",
    "#Plot A\n",
    "implot = ax_dict['A'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "nm=str('cou2cu')\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "i=int(np.where(nms==nm)[0])\n",
    "ax_dict['A'].scatter(filt[0],filt[1],s=2,rasterized=True,label=Fnms[i])\n",
    "nm=str('ouralu')\n",
    "i=int(np.where(nms==nm)[0])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "ax_dict['A'].scatter(filt[0],filt[1],s=2,color='red',rasterized=True,label=Fnms[i])\n",
    "lgd=ax_dict['A'].legend(ncol=2,loc='upper center',markerscale=10,columnspacing=0.4,handlelength=0.5,handletextpad=0.4,bbox_to_anchor=(0.5,1.2),fontsize=12)\n",
    "for legend_handle in lgd.legendHandles:\n",
    "    legend_handle.set_sizes([20])\n",
    "ax_dict['A'].set_xlim(0,1000)\n",
    "ax_dict['A'].set_ylim(0,500)\n",
    "\n",
    "ax_dict['A'].text(-0.05, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#Plot B\n",
    "implot = ax_dict['B'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "nm=str('guatdu')\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "i=int(np.where(nms==nm)[0])\n",
    "ax_dict['B'].scatter(filt[0],filt[1],s=2,rasterized=True,label=Fnms[i])\n",
    "nm=str('unonpi')\n",
    "i=int(np.where(nms==nm)[0])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "ax_dict['B'].scatter(filt[0],filt[1],s=2,color='red',rasterized=True,label=Fnms[i])\n",
    "lgd=ax_dict['B'].legend(ncol=2,loc='upper center',markerscale=10,columnspacing=0.4,handlelength=0.5,handletextpad=0.4,bbox_to_anchor=(0.5,1.2),fontsize=12)\n",
    "for legend_handle in lgd.legendHandles:\n",
    "    legend_handle.set_sizes([20])\n",
    "ax_dict['B'].set_xlim(0,1000)\n",
    "ax_dict['B'].set_ylim(0,500)\n",
    "\n",
    "ax_dict['B'].text(-0.05, 1.03, 'B', transform=ax_dict['B'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#Plot C\n",
    "implot = ax_dict['C'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "nm=str('faraoc')\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "i=int(np.where(nms==nm)[0])\n",
    "ax_dict['C'].scatter(filt[0],filt[1],s=0.1,rasterized=True,label=Fnms[i])\n",
    "nm=str('unonpi')\n",
    "i=int(np.where(nms==nm)[0])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "ax_dict['C'].scatter(filt[0],filt[1],s=2,color='red',rasterized=True,label=Fnms[i])\n",
    "lgd=ax_dict['C'].legend(ncol=2,loc='upper center',markerscale=10,columnspacing=0.4,handlelength=0.5,handletextpad=0.4,bbox_to_anchor=(0.5,1.2),fontsize=12)\n",
    "for legend_handle in lgd.legendHandles:\n",
    "    legend_handle.set_sizes([20])\n",
    "ax_dict['C'].set_xlim(0,1000)\n",
    "ax_dict['C'].set_ylim(0,500)\n",
    "\n",
    "ax_dict['C'].text(-0.05, 1.03, 'C', transform=ax_dict['C'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "#Plot B\n",
    "implot = ax_dict['D'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "nm=str('mourmy')\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "i=int(np.where(nms==nm)[0])\n",
    "ax_dict['D'].scatter(filt[0],filt[1],s=0.3,rasterized=True,label=Fnms[i])\n",
    "nm=str('drypst')\n",
    "i=int(np.where(nms==nm)[0])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "ax_dict['D'].scatter(filt[0],filt[1],s=0.3,color='red',rasterized=True,label=Fnms[i])\n",
    "lgd=ax_dict['D'].legend(ncol=2,loc='upper center',markerscale=10,columnspacing=0.4,handlelength=0.5,handletextpad=0.4,bbox_to_anchor=(0.5,1.2),fontsize=12)\n",
    "for legend_handle in lgd.legendHandles:\n",
    "    legend_handle.set_sizes([20])\n",
    "ax_dict['D'].set_xlim(0,1000)\n",
    "ax_dict['D'].set_ylim(0,500)\n",
    "\n",
    "ax_dict['D'].text(-0.05, 1.03, 'D', transform=ax_dict['D'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "plt.savefig('Species.pdf')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i in range(nspec):\n",
    "    nm=Recount[i][1]\n",
    "    N=Recount[i][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "    #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "    U=np.array((list(chain.from_iterable(hist))))\n",
    "    #np.random.shuffle(U)\n",
    "    UVec[i]=U\n",
    "#Corr1=scipy.stats.spearmanr(UVec,axis=1)\n",
    "Corr=np.corrcoef(UVec)\n",
    "N=100\n",
    "T=(Lx/Lb)*(Ly/Lb)\n",
    "C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc693b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(C1,0)\n",
    "np.fill_diagonal(Corr,0)\n",
    "C2=np.triu(C1)\n",
    "#C2=np.triu(Corr)\n",
    "#C2=np.triu(np.abs(np.abs(Corr)-np.abs(C1)))\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "\n",
    "topN=10\n",
    "small_elems = sorted(C2.ravel(),reverse=False)[:topN]\n",
    "for i in range(topN):\n",
    "    i1=np.where(C2==small_elems[i])[0][0]\n",
    "    j1=np.where(C2==small_elems[i])[1][0]\n",
    "    #if (np.abs(C1[i1,j1])>np.abs(Corr[i1,j1])):\n",
    "    print(Corr[i1,j1],C1[i1,j1],-Corr[i1,j1]+C1[i1,j1],i1,j1,Nombres[i1],Nombres[j1],i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "i=0\n",
    "i1=np.where(C2==small_elems[i])[0][0]\n",
    "j1=np.where(C2==small_elems[i])[1][0]\n",
    "\n",
    "\n",
    "BCI = pd.read_csv(\"bcitree8.dat\",delimiter=' ',header=None) \n",
    "Names = pd.read_csv(\"Names_BCI.csv\",delimiter=',',header=None) \n",
    "\n",
    "nms=Names[0]\n",
    "Fnms=Names[2]\n",
    "Nmbr=Names[1]\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(5,3)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AA\n",
    "    \"\"\"\n",
    ")\n",
    "im = plt.imread('Level.png')\n",
    "#Plot A\n",
    "implot = ax_dict['A'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "nm=str(Nombres[i1])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "i=int(np.where(nms==nm)[0])\n",
    "ax_dict['A'].scatter(filt[0],filt[1],s=0.1,rasterized=True,label=Fnms[i])\n",
    "nm=str(Nombres[j1])\n",
    "i=int(np.where(nms==nm)[0])\n",
    "filt = BCI[BCI[3] == nm.strip()]\n",
    "ax_dict['A'].scatter(filt[0],filt[1],s=2,color='red',rasterized=True,label=Fnms[i])\n",
    "lgd=ax_dict['A'].legend(ncol=2,loc='upper center',markerscale=10,columnspacing=0.4,handlelength=0.5,handletextpad=0.4,bbox_to_anchor=(0.5,1.2),fontsize=12)\n",
    "for legend_handle in lgd.legendHandles:\n",
    "    legend_handle.set_sizes([20])\n",
    "ax_dict['A'].set_xlim(0,1000)\n",
    "ax_dict['A'].set_ylim(0,500)\n",
    "\n",
    "ax_dict['A'].text(-0.05, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grid_communities(communities):\n",
    "    \"\"\"\n",
    "    Generates boundaries of `communities`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    communities : array_like\n",
    "        Community assignment vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bounds : list\n",
    "        Boundaries of communities\n",
    "    \"\"\"\n",
    "\n",
    "    communities = np.asarray(communities)\n",
    "    if 0 in communities:\n",
    "        communities = communities + 1\n",
    "\n",
    "    comm = communities[np.argsort(communities)]\n",
    "    bounds = []\n",
    "    for i in np.unique(comm):\n",
    "        ind = np.where(comm == i)\n",
    "        if len(ind) > 0:\n",
    "            bounds.append(np.min(ind))\n",
    "\n",
    "    bounds.append(len(communities))\n",
    "\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(9,3.5)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AABB\n",
    "    AABB\n",
    "    \"\"\"\n",
    ")\n",
    "#fig = plt.figure(constrained_layout=True,figsize=(10, 10))\n",
    "#ax_dict = fig.subplot_mosaic(layout)\n",
    "    \n",
    "#Take CMAP\n",
    "cmap1 = cmocean.cm.delta   #Green/blue\n",
    "cmap2 = cmocean.cm.balance #Red/blue\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i in range(nspec):\n",
    "    nm=Recount[i][1]\n",
    "    N=Recount[i][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "    #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "    U=np.array((list(chain.from_iterable(hist))))\n",
    "    #np.random.shuffle(U)\n",
    "    UVec[i]=U\n",
    "#Corr1=scipy.stats.spearmanr(UVec,axis=1)\n",
    "Corr=np.corrcoef(UVec)\n",
    "N=100\n",
    "T=(Lx/Lb)*(Ly/Lb)\n",
    "C1=MarchenkoPastur(Corr,N,T,remove_largest=False)\n",
    "\n",
    "# define your scale, with white at zero\n",
    "vmin = -0.5\n",
    "vmax = 0.5#np.max(A2)\n",
    "norm = colors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "pearson1=np.copy(C1)\n",
    "pearson1[pearson1<0]=0\n",
    "G = nx.from_numpy_array(np.abs(pearson1))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "L=nx.laplacian_matrix(G)\n",
    "L1=L.todense()\n",
    "w=1/nx.laplacian_spectrum(G)\n",
    "\n",
    "#Put a small value of tau here, we want macro-clusters\n",
    "#Control that clusters are stable along different values of tau\n",
    "#Th controls the threshold in the dendrogram, linkage can be changed from 'average' to 'complete'\n",
    "#Control also that this does not change the results\n",
    "tau=1e-3\n",
    "\n",
    "num=expm((-tau*L1))\n",
    "den=np.trace(num)\n",
    "rho=num/den\n",
    "\n",
    "Trho=np.copy(1.0/rho)#1/adj2\n",
    "Trho=np.tril(Trho) + np.triu(Trho.T, 1)\n",
    "np.fill_diagonal(Trho, 0)\n",
    "\n",
    "dists = squareform(Trho)\n",
    "linkage_matrix = linkage(dists, \"complete\")\n",
    "labelList = [i+1 for i in range(0, len(G.nodes()))]\n",
    "tmax=linkage_matrix[::, 2][-1]#+0.01*linkage_matrix[::, 2][-1]\n",
    "linkage_matrix = linkage(dists/tmax, \"complete\")\n",
    "CM=fcluster(linkage_matrix, t=Th, criterion='distance')\n",
    "\n",
    "idx   = np.argsort(CM)\n",
    "N=len(idx)\n",
    "comm = np.sort(CM)\n",
    "A2 = [[C1[i][j] for j in idx] for i in idx]\n",
    "\n",
    "im=ax_dict['A'].imshow(Corr,cmap=cmap2,rasterized='True',interpolation=None,norm=norm)\n",
    "ax_dict['A'].set_xticks([0,50,100])\n",
    "ax_dict['A'].set_yticks([0,50,100])\n",
    "ax_dict['A'].set_title(r'Pearson Corr. $\\ell=50m$',fontsize=12)\n",
    "ax_dict['A'].text(-0.23, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "im2=ax_dict['B'].imshow(A2,cmap=cmap2,rasterized='True',interpolation=None,norm=norm)\n",
    "ax_dict['B'].set_xticks([0,50,100])\n",
    "ax_dict['B'].set_yticks([0,50,100])\n",
    "ax_dict['B'].set_title(r'Filtered Corr. $\\ell=50m$',fontsize=12)\n",
    "ax_dict['B'].text(-0.23, 1.03, 'B', transform=ax_dict['B'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3779f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=10\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=100\n",
    "l=Lb\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "pal = sns.color_palette('Spectral', n_colors=nspec, desat=1.0)\n",
    "\n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i1 in range(20,20+nspec):\n",
    "    nm=Recount[i1][1]\n",
    "    N=Recount[i1][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    maxx=int(1000/l)\n",
    "    maxy=int(500/l)\n",
    "    nb=maxx*maxy\n",
    "    a=np.zeros((len(filt),2))\n",
    "    gx=np.array(filt[0])\n",
    "    gy=np.array(filt[1])\n",
    "    #gx = 1000*np.random.rand(len(gx))\n",
    "    #gy = 500*np.random.rand(len(gx))\n",
    "    for i in tqdm(range(len(filt))):\n",
    "        bx=int(gx[i]/(1.0*l))+1\n",
    "        by=int(gy[i]/(1.0*l))+1\n",
    "        if(gx[i]==Lx):\n",
    "            bx=maxx-1\n",
    "        if(gy[i]==Ly):\n",
    "            by=maxy-1\n",
    "        if(gx[i]==0):\n",
    "            bx=1\n",
    "        if(gy[i]==0):\n",
    "            by=1\n",
    "        if (((gx[i]/(1.0*l))>(1.0*maxx))&((gy[i]/(1.0*l))>(1.0*maxy))):\n",
    "            print('Error assigning points')\n",
    "        a[i]=[bx,by]\n",
    "\n",
    "    cont=0\n",
    "    a1=np.zeros((len(filt),2))\n",
    "    count=np.zeros((nb))\n",
    "    for i in range(maxx):\n",
    "        for j in range(maxy):\n",
    "            a1[cont]=[i+1,j+1]\n",
    "            count[cont]=cont\n",
    "            cont=cont+1\n",
    "\n",
    "    gx1=np.zeros(len(gx))\n",
    "    gy1=np.zeros(len(gx))\n",
    "    for i in range(len(filt)):\n",
    "        indx=np.where(np.sum(np.abs((a[i]-a1)),axis=1)==0)[0][0]\n",
    "        gx1[i]=gx[i]+1.0*l*np.where(np.sum(np.abs((a[i]-a1)),axis=1)==0)[0][0]\n",
    "        gy1[i]=gy[i]-1.0*(a1[indx,1]-1)*(l)+(i1-20)*l\n",
    "    #gx1=2*np.pi*gx1/(np.max(gx1))\n",
    "    # Scatter graph\n",
    "    ax.scatter(np.cos(gx1), np.sin(gx1), gy1,s=2,alpha=1.0,color=pal.pop(0),rasterized=True)\n",
    "    \n",
    "# Prepare arrays x, y, z\n",
    "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
    "z2 = 0.0\n",
    "r = 1.0\n",
    "x2 = r * np.sin(theta)\n",
    "y2 = r * np.cos(theta)\n",
    "#ax.plot(x2, y2, z2, label='parametric curve',color='black')\n",
    "for i in range(nspec+1):\n",
    "    ax.plot(x2, y2, z2+i*l, label='parametric curve',color='black')\n",
    "z3 = np.linspace(0,1,100)\n",
    "#ax.scatter(1, 0, z3, label='parametric curve',color='red')\n",
    "Nbox=int((Lx/l)*(Ly/l))\n",
    "for i in range(Nbox):\n",
    "    phi=i*2*np.pi/Nbox\n",
    "    ax.plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[0,nspec*l],\n",
    "            color = 'black',lw=1)\n",
    "    ax.plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[-70,0],\n",
    "            color = 'black',lw=1,ls=':')\n",
    "    ax.plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[nspec*l,nspec*l+70],\n",
    "            color = 'black',lw=1,ls=':')\n",
    "    \n",
    "ax.set_axis_off()    \n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "ax.view_init(elev=30, azim=45, roll=-5)\n",
    "plt.savefig('Cylinder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "#Compute Corr Matrix\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "l=Lb\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "\n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "nspec=len(np.unique(BCI[3]))\n",
    "pal = sns.color_palette('Set1', n_colors=nspec, desat=1.0)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i1 in tqdm(range(0,nspec)):\n",
    "    nm=Recount[i1][1]\n",
    "    N=Recount[i1][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    maxx=int(1000/l)\n",
    "    maxy=int(500/l)\n",
    "    nb=maxx*maxy\n",
    "    a=np.zeros((len(filt),2))\n",
    "    gx=np.array(filt[0])\n",
    "    gy=np.array(filt[1])\n",
    "    plt.scatter(gx,gy,color=pal.pop(0),s=0.001*(np.abs(np.array(filt[2]))),rasterized=True)\n",
    "    \n",
    "for i in range(int(Ly/l)):\n",
    "    plt.plot([0,Lx],[(i+1)*l,(i+1)*l],color = 'gray',lw=1,zorder=-5)\n",
    "for i in range(int(Lx/l)):\n",
    "    plt.plot([(i+1)*l,(i+1)*l],[0,Ly],color = 'gray',lw=1,zorder=-5)\n",
    "\n",
    "    \n",
    "    \n",
    "plt.xlim(0,1000)\n",
    "plt.ylim(0,500)\n",
    "plt.ylabel('y(m)')\n",
    "plt.xlabel('x(m)')\n",
    "plt.savefig('BCI-Scatter.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(6,6)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    CC\n",
    "    BA\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#EIGENVALUE DISTRIBUTION\n",
    "ax_dict['A'].set_ylabel(r'$\\lambda$')\n",
    "ax_dict['A'].set_xlabel(r'$P(\\lambda)$')\n",
    "\n",
    "\n",
    "#CYLINDER\n",
    "ax_dict['B'] =  plt.subplot(2,2,3, projection='3d')\n",
    "#Compute Corr Matrix\n",
    "nspec=10\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=100\n",
    "l=Lb\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "pal = sns.color_palette('Spectral', n_colors=nspec, desat=1.0)\n",
    "\n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i1 in range(20,20+nspec):\n",
    "    nm=Recount[i1][1]\n",
    "    N=Recount[i1][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    maxx=int(1000/l)\n",
    "    maxy=int(500/l)\n",
    "    nb=maxx*maxy\n",
    "    a=np.zeros((len(filt),2))\n",
    "    gx=np.array(filt[0])\n",
    "    gy=np.array(filt[1])\n",
    "    #gx = 1000*np.random.rand(len(gx))\n",
    "    #gy = 500*np.random.rand(len(gx))\n",
    "    for i in tqdm(range(len(filt))):\n",
    "        bx=int(gx[i]/(1.0*l))+1\n",
    "        by=int(gy[i]/(1.0*l))+1\n",
    "        if(gx[i]==Lx):\n",
    "            bx=maxx-1\n",
    "        if(gy[i]==Ly):\n",
    "            by=maxy-1\n",
    "        if(gx[i]==0):\n",
    "            bx=1\n",
    "        if(gy[i]==0):\n",
    "            by=1\n",
    "        if (((gx[i]/(1.0*l))>(1.0*maxx))&((gy[i]/(1.0*l))>(1.0*maxy))):\n",
    "            print('Error assigning points')\n",
    "        a[i]=[bx,by]\n",
    "\n",
    "    cont=0\n",
    "    a1=np.zeros((len(filt),2))\n",
    "    count=np.zeros((nb))\n",
    "    for i in range(maxx):\n",
    "        for j in range(maxy):\n",
    "            a1[cont]=[i+1,j+1]\n",
    "            count[cont]=cont\n",
    "            cont=cont+1\n",
    "\n",
    "    gx1=np.zeros(len(gx))\n",
    "    gy1=np.zeros(len(gx))\n",
    "    for i in range(len(filt)):\n",
    "        indx=np.where(np.sum(np.abs((a[i]-a1)),axis=1)==0)[0][0]\n",
    "        gx1[i]=gx[i]+1.0*l*np.where(np.sum(np.abs((a[i]-a1)),axis=1)==0)[0][0]\n",
    "        gy1[i]=gy[i]-1.0*(a1[indx,1]-1)*(l)+(i1-20)*l\n",
    "    #gx1=2*np.pi*gx1/(np.max(gx1))\n",
    "    # Scatter graph\n",
    "    ax_dict['B'].scatter(np.cos(gx1), np.sin(gx1), gy1,s=2,alpha=1.0,color=pal.pop(0),rasterized=True)\n",
    "    \n",
    "# Prepare arrays x, y, z\n",
    "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
    "z2 = 0.0\n",
    "r = 1.0\n",
    "x2 = r * np.sin(theta)\n",
    "y2 = r * np.cos(theta)\n",
    "#ax.plot(x2, y2, z2, label='parametric curve',color='black')\n",
    "for i in range(nspec+1):\n",
    "    ax_dict['B'].plot(x2, y2, z2+i*l, label='parametric curve',color='black')\n",
    "z3 = np.linspace(0,1,100)\n",
    "#ax.scatter(1, 0, z3, label='parametric curve',color='red')\n",
    "Nbox=int((Lx/l)*(Ly/l))\n",
    "for i in range(Nbox):\n",
    "    phi=i*2*np.pi/Nbox\n",
    "    ax_dict['B'].plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[0,nspec*l],\n",
    "            color = 'black',lw=1)\n",
    "    ax_dict['B'].plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[-70,0],\n",
    "            color = 'black',lw=1,ls=':')\n",
    "    ax_dict['B'].plot([r*np.cos(phi),r*np.cos(phi)],[r*np.sin(phi),r*np.sin(phi)],[nspec*l,nspec*l+70],\n",
    "            color = 'black',lw=1,ls=':')\n",
    "    \n",
    "ax_dict['B'].set_axis_off()    \n",
    "ax_dict['B'].set_xticks([])\n",
    "ax_dict['B'].set_yticks([])\n",
    "ax_dict['B'].set_zticks([])\n",
    "ax_dict['B'].view_init(elev=30, azim=45, roll=-5)\n",
    "\n",
    "#SCATTER PLOT\n",
    "#Compute Corr Matrix\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "l=Lb\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "\n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "nspec=len(np.unique(BCI[3]))\n",
    "pal = sns.color_palette('Set1', n_colors=nspec, desat=1.0)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i1 in tqdm(range(0,nspec)):\n",
    "    nm=Recount[i1][1]\n",
    "    N=Recount[i1][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    maxx=int(1000/l)\n",
    "    maxy=int(500/l)\n",
    "    nb=maxx*maxy\n",
    "    a=np.zeros((len(filt),2))\n",
    "    gx=np.array(filt[0])\n",
    "    gy=np.array(filt[1])\n",
    "    ax_dict['C'].scatter(gx,gy,color=pal.pop(0),s=0.001*(np.abs(np.array(filt[2]))),rasterized=True)\n",
    "    \n",
    "for i in range(int(Ly/l)):\n",
    "    ax_dict['C'].plot([0,Lx],[(i+1)*l,(i+1)*l],color = 'gray',lw=1,zorder=-5)\n",
    "for i in range(int(Lx/l)):\n",
    "    ax_dict['C'].plot([(i+1)*l,(i+1)*l],[0,Ly],color = 'gray',lw=1,zorder=-5)\n",
    "\n",
    "    \n",
    "    \n",
    "ax_dict['C'].set_xlim(0,1000)\n",
    "ax_dict['C'].set_ylim(0,500)\n",
    "ax_dict['C'].set_ylabel('y(m)')\n",
    "ax_dict['C'].set_xlabel('x(m)')\n",
    "\n",
    "plt.savefig('Sketch.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1456e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "eigs1=[]\n",
    "#Select Census\n",
    "for j in range(8,9):\n",
    "    print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        filt[0] = 1000*np.random.rand(len(filt[0]))\n",
    "        filt[1] = 500*np.random.rand(len(filt[1]))\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        UVec[i]=U\n",
    "    Corr=np.corrcoef(UVec)\n",
    "    w1=np.abs(np.linalg.eigvalsh(Corr))\n",
    "    eigs1=np.concatenate((eigs1, w1), axis=None)\n",
    "    for nreps in tqdm(range(1000)):\n",
    "        UVec1=np.copy(UVec)\n",
    "        #for k in range(10):\n",
    "        posit=random.sample(range(1, len(U)-1), nspec)\n",
    "        for i in range(nspec):\n",
    "            #posit=1+random.randrange(len(U)-1)\n",
    "            #U=np.array(UVec[i])\n",
    "            #np.random.shuffle(U)\n",
    "            #UVec1[i]=U\n",
    "            UVec1[i]=np.roll(UVec[i],posit[i])\n",
    "\n",
    "        Corr=np.corrcoef(UVec1)\n",
    "        w=np.abs(np.linalg.eigvalsh(Corr))\n",
    "        eigs=np.concatenate((eigs, w), axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "from scipy.ndimage import gaussian_filter\n",
    "#eigs=np.copy(w)\n",
    "#probc,binsc=np.histogram(eigs,np.arange(8e-2,2*np.max(eigs),0.01),density=True)\n",
    "fit1=powerlaw.Fit(eigs,xmin=1e-2,xmax=2*np.max(eigs),discrete=False,density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "\n",
    "np.save('Census_'+str(j)+'_l_'+str(Lb)+'_Eigs_Random.npy', [binsc,probc])\n",
    "T=len(U)\n",
    "print(T)\n",
    "gamma=(1.0*nspec)/T\n",
    "print(gamma)\n",
    "x=np.arange(1e-4, 1e2, 0.001)\n",
    "data=marchpast(x,gamma)\n",
    "data[data == 0] = 'nan'\n",
    "\n",
    "plt.plot(x, data)\n",
    "\n",
    "#probc[probc == 0] = 'nan'\n",
    "#binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "probc[probc == 0] = 'nan'\n",
    "result = gaussian_filter(probc, sigma=0.1)\n",
    "plt.plot(binsc,result,lw=0.5,marker='o',markersize=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#eigs=np.copy(w1)\n",
    "fit1=powerlaw.Fit(eigs1,xmin=1e-3,xmax=2*np.max(eigs1),discrete=False,\n",
    "                  density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "#probc,binsc=np.histogram(eigs1,np.arange(5e-2,2*np.max(eigs),0.1),density=True)\n",
    "#probc,binsc=np.histogram(eigs1,np.arange(1e-2,2*np.max(eigs1),0.05),density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "probc[probc == 0] = 'nan'\n",
    "plt.plot(binsc,probc,marker='o',lw=2,color='black')\n",
    "\n",
    "plt.axhline(y=2/T)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(eigs[eigs>1e-3]))\n",
    "print(np.min(eigs1[eigs1>1e-3]))\n",
    "\n",
    "print(np.max(eigs[eigs>1e-3]))\n",
    "print(np.max(eigs1[eigs1>1e-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79495e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "#eigs=np.copy(w)\n",
    "#probc,binsc=np.histogram(eigs,np.arange(0.5*np.min(eigs),2*np.max(eigs),0.05),density=True)\n",
    "fit1=powerlaw.Fit(eigs,xmin=1e-2,xmax=2*np.max(eigs),discrete=False,density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "\n",
    "T=len(U)\n",
    "print(T)\n",
    "gamma=(1.0*nspec)/T\n",
    "print(gamma)\n",
    "x=np.arange(1e-4, 1e2, 0.001)\n",
    "data=marchpast(x,gamma)\n",
    "data[data == 0] = 'nan'\n",
    "\n",
    "plt.plot(x, data)\n",
    "\n",
    "#probc[probc == 0] = 'nan'\n",
    "#binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "probc[probc <= 5e-4] = 0\n",
    "plt.plot(binsc,probc,marker='o',lw=3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_intersections(x, y, C):\n",
    "    # Contains numpy indexing tricks that can be hard to reproduce\n",
    "    # in the case where both functions are non-constants\n",
    "    ii, = np.nonzero((y[1:]-C)*(y[:-1]-C) < 0.)  # intersection indices\n",
    "    x_intersections = x[ii] + (C - y[ii])/(y[1+ii] - y[ii])*(x[1+ii] - x[ii])\n",
    "    y_intersections = C * np.ones(len(ii))\n",
    "    return x_intersections, y_intersections\n",
    "\n",
    "\n",
    "xint, yint = find_intersections(binsc, probc, 1e-2)\n",
    "print(xint,yint)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(8,9):\n",
    "    print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        UVec[i]=U\n",
    "    Corr=np.corrcoef(UVec)\n",
    "\n",
    "\n",
    "w, v = np.linalg.eigh(Corr)  # Spectral decomposition of C\n",
    "    \n",
    "w_min = 0.23\n",
    "w_max = 3.97\n",
    "\n",
    "selected = (w < w_min) | (w > w_max)\n",
    "\n",
    "\n",
    "w_signal = w[selected]\n",
    "v_signal = v[:, selected]\n",
    "\n",
    "C_new = v_signal.dot(np.diag(w_signal)).dot(v_signal.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean\n",
    "\n",
    "cmap2 = cmocean.cm.balance #Red/blue\n",
    "\n",
    "plt.imshow(C_new,cmap=cmap2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.load('Census_8_l_100_Eigs_Random.npy')\n",
    "plt.plot(p[0],p[1])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim(1e-3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36724c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(UVec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f24e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(UVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.datasets import make_blobs\n",
    "import gc\n",
    "import sys\n",
    "from numpy import random\n",
    "import powerlaw\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import scipy.stats\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from itertools import chain\n",
    "import powerlaw\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(8,3)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    CCA\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#SCATTER PLOT\n",
    "#Compute Corr Matrix\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "l=Lb\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "\n",
    "#Select Census\n",
    "j=8\n",
    "print('Census '+str(j))\n",
    "BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "\n",
    "#Select the more abundant species\n",
    "#nm=str('hybapr')\n",
    "Count=np.zeros(len(Names),dtype=int)\n",
    "nspec=len(np.unique(BCI[3]))\n",
    "pal = sns.color_palette('Set1', n_colors=nspec, desat=1.0)\n",
    "cont=0\n",
    "for nm in Names[0]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    Count[cont]=len(filt[3])\n",
    "    cont=cont+1\n",
    "\n",
    "Recount=list(zip(Count,Names[0]))\n",
    "Recount.sort(reverse=True)\n",
    "UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "for i1 in tqdm(range(0,nspec)):\n",
    "    nm=Recount[i1][1]\n",
    "    N=Recount[i1][0]\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    maxx=int(1000/l)\n",
    "    maxy=int(500/l)\n",
    "    nb=maxx*maxy\n",
    "    a=np.zeros((len(filt),2))\n",
    "    gx=np.array(filt[0])\n",
    "    gy=np.array(filt[1])\n",
    "    #*np.log10(1+np.abs(np.array(filt[2])))\n",
    "    ax_dict['C'].scatter(gx,gy,color=pal.pop(0),marker=MarkerStyle(\"o\", fillstyle=\"full\"),\n",
    "                         edgecolors='none',s=0.125,\n",
    "                         rasterized=True)\n",
    "    \n",
    "for i in range(int(Ly/l)):\n",
    "    ax_dict['C'].plot([0,Lx],[(i+1)*l,(i+1)*l],color = 'gray',lw=1,zorder=-5)\n",
    "for i in range(int(Lx/l)):\n",
    "    ax_dict['C'].plot([(i+1)*l,(i+1)*l],[0,Ly],color = 'gray',lw=1,zorder=-5)\n",
    "\n",
    "    \n",
    "    \n",
    "ax_dict['C'].set_xlim(0,1000)\n",
    "ax_dict['C'].set_ylim(0,500)\n",
    "ax_dict['C'].set_ylabel('y(m)')\n",
    "ax_dict['C'].set_xlabel('x(m)')\n",
    "\n",
    "#Compute Corr Matrix\n",
    "nspec=100\n",
    "Lx=1000\n",
    "Ly=500\n",
    "Lb=50\n",
    "Names = pd.read_csv(\"NamesBCI\",delimiter=' ',header=None)\n",
    "eigs=[]\n",
    "eigs1=[]\n",
    "#Select Census\n",
    "for j in tqdm(range(1,9)):\n",
    "    #print('Census '+str(j))\n",
    "    BCI = pd.read_csv('bcitree'+str(j)+'.dat',delimiter=' ',header=None) \n",
    "    #Select the more abundant species\n",
    "    #nm=str('hybapr')\n",
    "    Count=np.zeros(len(Names),dtype=int)\n",
    "    cont=0\n",
    "    for nm in Names[0]:\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        Count[cont]=len(filt[3])\n",
    "        cont=cont+1\n",
    "\n",
    "    Recount=list(zip(Count,Names[0]))\n",
    "    Recount.sort(reverse=True)\n",
    "    UVec=np.zeros((nspec,int(Lx/Lb*Ly/Lb)))\n",
    "    for i in range(nspec):\n",
    "        nm=Recount[i][1]\n",
    "        N=Recount[i][0]\n",
    "        filt = BCI[BCI[3] == nm.strip()]\n",
    "        hist, xedges, yedges = np.histogram2d(filt[1], filt[0], bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "        #UVec= np.vstack([UVec, np.array(list(chain.from_iterable(hist)))])\n",
    "        U=np.array((list(chain.from_iterable(hist))))\n",
    "        UVec[i]=U\n",
    "    Corr=np.corrcoef(UVec)\n",
    "    w1=np.abs(np.linalg.eigvalsh(Corr))\n",
    "    eigs1=np.concatenate((eigs1, w1), axis=None)\n",
    "    for nreps in (range(10)):\n",
    "        UVec1=np.copy(UVec)\n",
    "        #for k in range(10):\n",
    "        #posit=random.sample(range(1, len(U)-1), nspec)\n",
    "        for i in range(nspec):\n",
    "            #posit=1+random.randrange(len(U)-1)\n",
    "            U=np.array(UVec[i])\n",
    "            np.random.shuffle(U)\n",
    "            #UVec1[i]=U\n",
    "            UVec1[i]=U\n",
    "\n",
    "        Corr=np.corrcoef(UVec1)\n",
    "        w=np.abs(np.linalg.eigvalsh(Corr))\n",
    "        eigs=np.concatenate((eigs, w), axis=None)\n",
    "\n",
    "\n",
    "#EIGENVALUE DISTRIBUTION\n",
    "#eigs=np.copy(w)\n",
    "#probc,binsc=np.histogram(eigs,np.arange(1e-3,2*np.max(eigs),0.01),density=True)\n",
    "fit1=powerlaw.Fit(eigs,xmin=1e-3,xmax=2*np.max(eigs),discrete=False,density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "\n",
    "T=len(U)\n",
    "print(T)\n",
    "gamma=(1.0*nspec)/T\n",
    "print(gamma)\n",
    "x=np.arange(1e-4, 1e2, 0.001)\n",
    "data=marchpast(x,gamma)\n",
    "data[data == 0] = 'nan'\n",
    "\n",
    "ax_dict['A'].plot(x, data,color='crimson',ls='--')\n",
    "\n",
    "probc[probc == 0] = 'nan'\n",
    "result = gaussian_filter(probc, sigma=0.1)\n",
    "ax_dict['A'].plot(binsc,result,marker='o',lw=0.5,zorder=-5,color='crimson')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#eigs=np.copy(w1)\n",
    "fit1=powerlaw.Fit(eigs1,xmin=1e-3,xmax=2*np.max(eigs1),discrete=False,\n",
    "                  density=True,fit_method='KS')\n",
    "binsc, probc=fit1.pdf(linear_bins=False,density=True)\n",
    "#probc,binsc=np.histogram(eigs1,np.arange(5e-2,2*np.max(eigs),0.1),density=True)\n",
    "#probc,binsc=np.histogram(eigs1,np.arange(1e-2,2*np.max(eigs1),0.05),density=True)\n",
    "binsc = (binsc[1:]+binsc[:-1])/2.0\n",
    "probc[probc == 0] = 'nan'\n",
    "ax_dict['A'].plot(binsc,probc,marker='o',lw=2,color='dodgerblue')\n",
    "\n",
    "\n",
    "ax_dict['A'].set_xscale('log')\n",
    "ax_dict['A'].set_yscale('log')\n",
    "ax_dict['A'].set_ylim(1e-3,4)\n",
    "\n",
    "\n",
    "ax_dict['A'].set_xlabel(r'$\\lambda$')\n",
    "ax_dict['A'].set_ylabel(r'$P(\\lambda)$')\n",
    "\n",
    "ax_dict['A'].text(-0.5, 1.03, 'B', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "ax_dict['C'].text(-0.23, 1.03, 'A', transform=ax_dict['C'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "\n",
    "plt.savefig('Sketch.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmocean\n",
    "\n",
    "BCI = pd.read_csv(\"bcitree8.dat\",delimiter=' ',header=None) \n",
    "Names = pd.read_csv(\"Names_BCI.csv\",delimiter=',',header=None) \n",
    "\n",
    "nms=Names[0]\n",
    "Fnms=Names[2]\n",
    "Nmbr=Names[1]\n",
    "\n",
    "ax_dict = plt.figure(constrained_layout=True,figsize=(10,6)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AABB\n",
    "    CCDD\n",
    "    \"\"\"\n",
    ")\n",
    "im = plt.imread('Level.png')\n",
    "#Plot A\n",
    "implot = ax_dict['A'].imshow(im[::-1],origin='lower',alpha=0.8)\n",
    "index=np.where(CM==15)[0]\n",
    "pal = sns.color_palette('cmo.algae', n_colors=len(index), desat=1.0)\n",
    "\n",
    "Nombres=np.array(Recount)[:,1][0:100]\n",
    "gx=[]\n",
    "gy=[]\n",
    "for nm in Nombres[index]:\n",
    "    filt = BCI[BCI[3] == nm.strip()]\n",
    "    gx = np.append(gx,filt[0])\n",
    "    gy = np.append(gy,filt[1])\n",
    "    i=int(np.where(nms==nm)[0])\n",
    "    if (i>2):\n",
    "        ax_dict['A'].scatter(filt[0],filt[1],s=10/(len(index)*np.log10(len(filt))),\n",
    "                         rasterized=True,marker='.',label=Fnms[i],color='forestgreen')\n",
    "hist, xedges, yedges = np.histogram2d(filt[1], filt[0],\n",
    "                                      bins=[int(Ly/Lb),int(Lx/Lb)], range=[[0, Ly], [0, Lx]])\n",
    "ax_dict['A'].set_xlim(0,1000)\n",
    "ax_dict['A'].set_ylim(0,500)\n",
    "ax_dict['A'].set_title('Old Forest, Slope')\n",
    "ax_dict['A'].text(-0.05, 1.03, 'A', transform=ax_dict['A'].transAxes, \n",
    "            size=16, weight='bold')\n",
    "\n",
    "l=10\n",
    "implot = ax_dict['B'].imshow(im[::-1],origin='lower',alpha=0.5,zorder=10)\n",
    "h, x, y, p = ax_dict['C'].hist2d(gx, gy, bins=(int(Lx/l), int(Ly/l)),cmap='Greens')\n",
    "#Plot A\n",
    "im=ax_dict['B'].imshow(np.transpose(h/(l*l)), origin = \"lower\", \n",
    "                    interpolation = 'lanczos',\n",
    "                       cmap='Greens',extent=[0,1000,0,500],\n",
    "                      vmin=0,vmax=np.mean(h/(l*l))+3*np.std(h/(l*l)))\n",
    "ax_dict['B'].set_xlim(0,1000)\n",
    "ax_dict['B'].set_ylim(0,500)\n",
    "plt.colorbar(im,shrink=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=5\n",
    "plt.hist2d(gx, gy, bins=(int(Lx/l), int(Ly/l)), cmap='Greens')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(h/(l*l))+np.std(h/(l*l)))\n",
    "print(np.std(h/(l*l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca8698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
